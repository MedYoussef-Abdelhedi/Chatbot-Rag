
# ü§ñ Chatbot RAG : Assistant Documentaire Intelligent

![Python](https://img.shields.io/badge/Python-3.10%2B-blue?style=for-the-badge&logo=python)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-PgVector-336791?style=for-the-badge&logo=postgresql)
![Groq](https://img.shields.io/badge/AI-Groq%20Llama3-orange?style=for-the-badge)

Ce projet impl√©mente un syst√®me de **RAG (Retrieval-Augmented Generation)** haute performance. Il permet d'interagir avec une base de connaissances priv√©e (fichiers textes) via une interface conversationnelle.

Le syst√®me combine la confidentialit√© des **embeddings locaux** (via SentenceTransformers) avec la puissance et la rapidit√© de l'API **Groq (Llama 3.3)** pour la g√©n√©ration de r√©ponses.

---

## üèóÔ∏è Architecture du Projet

Le fonctionnement repose sur deux pipelines distincts :

1.  **Pipeline d'Ingestion (Indexation)** :
    *   Lecture des documents bruts dans le dossier `Data/`.
    *   D√©coupage (Chunking) et nettoyage du texte.
    *   Vectorisation via le mod√®le local `paraphrase-multilingual-mpnet-base-v2` (Dimension 768).
    *   Stockage dans **PostgreSQL** avec l'extension `pgvector`.

2.  **Pipeline de Chat (Inf√©rence)** :
    *   Analyse de la question utilisateur.
    *   Recherche s√©mantique (Cosine Similarity) dans PostgreSQL pour trouver les passages pertinents.
    *   Construction du prompt avec le contexte r√©cup√©r√©.
    *   G√©n√©ration de la r√©ponse via **Groq (Llama 3.3-70b)**.

---

## üìÇ Structure du Projet

```text
Chatbot-Rag/
‚îú‚îÄ‚îÄ Data/                               # üìÅ Base de connaissances (vos fichiers .txt)
‚îú‚îÄ‚îÄ main_console.py                     # üöÄ Interface Principale (Console + Groq API)
‚îú‚îÄ‚îÄ Model_embedding_plusPerformanat.py  # ‚öôÔ∏è Script d'Indexation (Embedding -> DB)
‚îú‚îÄ‚îÄ requirements.txt                    # üì¶ D√©pendances Python
‚îî‚îÄ‚îÄ README.md                           # üìÑ Documentation
```
üöÄ Installation et Configuration
1. Cloner le projet
code
Bash
download
content_copy
expand_less
git clone https://github.com/votre-compte/Chatbot-Rag.git
cd Chatbot-Rag
2. Cr√©er l'environnement virtuel
code
Bash
download
content_copy
expand_less
# Windows
python -m venv venv
.\venv\Scripts\activate

# Mac / Linux
python3 -m venv venv
source venv/bin/activate
3. Installer les d√©pendances
code
Bash
download
content_copy
expand_less
pip install -r requirement.txt
4. Configuration de la Base de Donn√©es (PostgreSQL)

Connectez-vous √† votre base de donn√©es et ex√©cutez ces commandes :

code
SQL
download
content_copy
expand_less
-- 1. Cr√©er la base de donn√©es
CREATE DATABASE rag_chatbot;

-- 2. Se connecter √† la base
\c rag_chatbot

-- 3. Activer l'extension vectorielle (INDISPENSABLE)
CREATE EXTENSION IF NOT EXISTS vector;
üíª Utilisation
√âtape 1 : Indexer vos documents (Ingestion)

Placez vos fichiers dans le dossier Data et lancez :

code
Bash
download
content_copy
expand_less
python Model_embedding_plusPerformanat.py
√âtape 2 : Lancer le Chatbot

Une fois l'indexation termin√©e :

code
Bash
download
content_copy
expand_less
python main_console.py
‚öôÔ∏è Configuration de l'API

Pour utiliser le mod√®le Llama 3.3, modifiez la cl√© dans main_console.py :

code
Python
download
content_copy
expand_less
GROQ_API_KEY = "gsk_votre_cle_api_ici..."
üìä Performances Techniques

Embedding : sentence-transformers/paraphrase-multilingual-mpnet-base-v2 (Dim 768).

LLM : Llama-3.3-70b-versatile via Groq (Inf√©rence ultra-rapide).

Base de Donn√©es : PostgreSQL + pgvector (Recherche par similarit√© cosinus).

code
Code
download
content_copy
expand_less
### Pour v√©rifier que c'est bon dans VS Code :
Une fois coll√©, faites le raccourci **`Ctrl + Shift + V`**. Cela ouvrira l'aper√ßu du README. Vous devriez voir des belles bo√Ætes de code s√©par√©es et non plus un seul gros bloc gris.